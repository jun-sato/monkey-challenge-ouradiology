{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5abbf4-91c4-495d-a0e1-5791544d3ba4",
   "metadata": {},
   "source": [
    "# Step 3: Creating the model inference script\n",
    "To submit your algorithm to the challenge, you need to create an inference docker container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84728b1-6166-400b-8ff7-312fc87145bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import creationism\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from wholeslidedata.interoperability.asap.annotationwriter import write_point_set\n",
    "from wholeslidedata.image.wholeslideimage import WholeSlideImage\n",
    "from wholeslidedata.iterators import create_patch_iterator, PatchConfiguration\n",
    "from wholeslidedata.annotation.labels import Label\n",
    "\n",
    "from utils.wsdetectron2 import Detectron2DetectionPredictor\n",
    "from utils.structures import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcf108-70f5-4339-be0e-358e07909d3a",
   "metadata": {},
   "source": [
    "Setting up the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f91aee-5195-4366-9c2d-73542eb65e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch GPU available: True\n",
      "./data/images/pas-cpg/A_P000002_PAS_CPG.tif ./data/images/tissue-masks/A_P000002_mask.tif\n"
     ]
    }
   ],
   "source": [
    "image_path = r'./data/images/pas-cpg/A_P000002_PAS_CPG.tif'\n",
    "mask_path = r'./data/images/tissue-masks/A_P000002_mask.tif'\n",
    "output_path = r\"./outputs/results\"\n",
    "if not(os.path.isdir(output_path)): os.mkdir (output_path) \n",
    "json_filename = \"detected-lymphocytes.json\"\n",
    "\n",
    "print(f\"Pytorch GPU available: {torch.cuda.is_available()}\")\n",
    "print(image_path, mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1031a-b590-4917-86e1-768a31a71147",
   "metadata": {},
   "source": [
    "Defining patch configuration for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f99bab4-b6e2-45fc-9b5d-1ff12437b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shape=(128, 128,3)\n",
    "spacings=(0.5,)\n",
    "overlap=(64,64)\n",
    "offset=(0,0)\n",
    "center=False\n",
    "\n",
    "patch_configuration = PatchConfiguration(patch_shape=patch_shape,\n",
    "                                         spacings=spacings,\n",
    "                                         overlap=overlap,\n",
    "                                         offset=offset,\n",
    "                                         center=center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86930aa-5184-46c1-b9c0-13e723d56bdb",
   "metadata": {},
   "source": [
    "Loading the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4122d05f-8153-4dde-9abf-362b8311217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jubuntu/anaconda3/envs/monkey/lib/python3.10/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "model = Detectron2DetectionPredictor(\n",
    "    output_dir=output_path,\n",
    "    threshold= 0.2,\n",
    "    nms_threshold=0.1,\n",
    "    weight_root = \"./outputs/model_final.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4167cee-bdb9-4f8a-9103-e97c9ce31ac0",
   "metadata": {},
   "source": [
    "Creating a patch iterator using the roi mask and sliding windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b3e546-321f-4797-8649-cceeed9a5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = create_patch_iterator(image_path=image_path,\n",
    "                               mask_path=mask_path,\n",
    "                               patch_configuration=patch_configuration,\n",
    "                               cpus=4,\n",
    "                               backend='asap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9487fdd-67d7-4d1a-aff0-fbff7bb63b2e",
   "metadata": {},
   "source": [
    "Some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eb0e923-9a7d-4cca-924f-f6383a9cddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def px_to_mm(px: int, spacing: float):\n",
    "    return px * spacing / 1000\n",
    "\n",
    "def to_wsd(points):\n",
    "    \"\"\"Convert list of coordinates into WSD points\"\"\"\n",
    "    new_points = []\n",
    "    for i, point in enumerate(points):\n",
    "        p = Point(\n",
    "            index=i,\n",
    "            label=Label(\"lymphocyted\", 1, color=\"blue\"),\n",
    "            coordinates=[point],\n",
    "        )\n",
    "        new_points.append(p)\n",
    "    return new_points\n",
    "\n",
    "def write_json_file(*, location, content):\n",
    "    # Writes a json file\n",
    "    with open(location, 'w') as f:\n",
    "        f.write(json.dumps(content, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6511c62-3c21-4f7d-8dc7-2246459c8ec7",
   "metadata": {},
   "source": [
    "Run inference on an image with loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7e6e3-5bb5-4dd7-a9d4-7097700691de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_thresholds = {\n",
    "    \"lymphocyte\": 0.7,  # lymphocyte用のthreshold例\n",
    "    \"monocyte\": 0.35     # monocyte用のthreshold例\n",
    "}\n",
    "\n",
    "def inference(iterator, predictor, spacing, image_path, output_path, json_filename):\n",
    "    print(\"predicting...\")\n",
    "    output_dict = {\n",
    "        \"name\": \"lymphocytes\",\n",
    "        \"type\": \"Multiple points\",\n",
    "        \"version\": {\"major\": 1, \"minor\": 0},\n",
    "        \"points\": [],\n",
    "    }\n",
    "\n",
    "    output_dict_monocytes = {\n",
    "        \"name\": \"monocytes\",\n",
    "        \"type\": \"Multiple points\",\n",
    "        \"version\": {\"major\": 1, \"minor\": 0},\n",
    "        \"points\": [],\n",
    "    }\n",
    "\n",
    "    output_dict_inflammatory_cells = {\n",
    "        \"name\": \"inflammatory-cells\",\n",
    "        \"type\": \"Multiple points\",\n",
    "        \"version\": {\"major\": 1, \"minor\": 0},\n",
    "        \"points\": [],\n",
    "    }\n",
    "\n",
    "    annotations = []\n",
    "    counter = 0\n",
    "    \n",
    "    spacing_min = 0.25\n",
    "    ratio = spacing/spacing_min\n",
    "    with WholeSlideImage(image_path) as wsi:\n",
    "        spacing = wsi.get_real_spacing(spacing_min)\n",
    "\n",
    "\n",
    "    for x_batch, y_batch, info in tqdm(iterator):\n",
    "        x_batch = x_batch.squeeze(0)\n",
    "        y_batch = y_batch.squeeze(0)\n",
    "\n",
    "        predictions = predictor.predict_on_batch(x_batch)\n",
    "        for idx, prediction in enumerate(predictions):\n",
    "\n",
    "            c = info['x']\n",
    "            r = info['y']\n",
    "\n",
    "            for detections in prediction:\n",
    "                x, y, label, confidence = detections.values()\n",
    "                #print(f'x: {x}, y: {y}, label: {label}, confidence: {confidence}')\n",
    "                if confidence < class_thresholds[label]:\n",
    "                    continue\n",
    "                \n",
    "                if x == 128 or y == 128:\n",
    "                    continue\n",
    "\n",
    "                if y_batch[idx][y][x] == 0:\n",
    "                    continue\n",
    "                \n",
    "                x = x*ratio + c # x is in spacing= 0.5 but c is in spacing = 0.25\n",
    "                y= y*ratio + r\n",
    "                prediction_record = {\n",
    "                    \"name\" : \"Point \"+str(counter),\n",
    "                    \"point\": [\n",
    "                        px_to_mm(x, spacing),\n",
    "                        px_to_mm(y, spacing),\n",
    "                        0.24199951445730394,\n",
    "                    ],\n",
    "                    \"probability\": confidence,\n",
    "                }\n",
    "                \n",
    "                if label == 'lymphocyte':\n",
    "                    output_dict[\"points\"].append(prediction_record)\n",
    "                    output_dict_inflammatory_cells[\"points\"].append(prediction_record)\n",
    "                elif label == 'monocyte':\n",
    "                    output_dict_monocytes[\"points\"].append(prediction_record)\n",
    "                    output_dict_inflammatory_cells[\"points\"].append(prediction_record)\n",
    "                \n",
    "                annotations.append((x, y))\n",
    "                counter += 1\n",
    "\n",
    "    print(len(output_dict[\"points\"]),len(output_dict_monocytes[\"points\"]),len(output_dict_inflammatory_cells[\"points\"]))  \n",
    "\n",
    "    print(f\"Predicted {len(annotations)} points\")\n",
    "    print(\"saving predictions...\")\n",
    "\n",
    "    # saving xml file\n",
    "    annotations_wsd = to_wsd(annotations)\n",
    "    xml_filename = 'points_results.xml'\n",
    "    output_path_xml = os.path.join(output_path,xml_filename)\n",
    "    write_point_set(\n",
    "        annotations_wsd,\n",
    "        output_path_xml,\n",
    "        label_color=\"blue\",\n",
    "    )\n",
    "\n",
    "    # saving json file\n",
    "    output_path_json = os.path.join(output_path, json_filename)\n",
    "    write_json_file(\n",
    "        location=output_path_json,\n",
    "        content=output_dict\n",
    "    )\n",
    "\n",
    "    json_filename_monocytes = \"detected-monocytes.json\"\n",
    "    # it should be replaced with correct json files\n",
    "    output_path_json = os.path.join(output_path, json_filename_monocytes)\n",
    "    write_json_file(\n",
    "        location=output_path_json,\n",
    "        content=output_dict_monocytes\n",
    "    )\n",
    "\n",
    "    json_filename_inflammatory_cells = \"detected-inflammatory-cells.json\"\n",
    "    # it should be replaced with correct json files\n",
    "    output_path_json = os.path.join(output_path, json_filename_inflammatory_cells)\n",
    "    write_json_file(\n",
    "        location=output_path_json,\n",
    "        content=output_dict_inflammatory_cells\n",
    "    )\n",
    "\n",
    "    print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf43390-c419-4b8a-9f5a-104cb8040592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jubuntu/anaconda3/envs/monkey/lib/python3.10/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647382455/work/aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 1506/1506 [00:26<00:00, 57.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 89 368\n",
      "Predicted 368 points\n",
      "saving predictions...\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "inference(\n",
    "    iterator=iterator,\n",
    "    predictor=model,\n",
    "    spacing = spacings[0],\n",
    "    image_path=image_path,\n",
    "    output_path=output_path,\n",
    "    json_filename=json_filename\n",
    ")\n",
    "\n",
    "iterator.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71124d71-9322-4cd8-b608-d80c1ea90e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /mnt/hdd2/monkey-challenge/algorithm-tutorial/outputs/results/*.json /mnt/hdd2/monkey-challenge/evaluation/test/input/A_P000002/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83028ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e487287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfc0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d2cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1b45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monkey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
