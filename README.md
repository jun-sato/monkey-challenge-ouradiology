# ouradiology team approach for the MONKEY challenge

This repository contains all tutorials and code for the MONKEY challenge on [Grand Challenge](https://monkey.grand-challenge.org/).  
We are grateful for the [Baseline code](https://github.com/computationalpathologygroup/monkey-challenge) used as a starting point.

---

## Our Ensemble-Based Approach

Instead of a single baseline model, we **train two models** that share the same baseline architecture but differ in **two key aspects**:

1. **Preprocessing Spacing**: 0.25 vs. 0.3  
2. **Loss Function**: Focal + DIoU vs. L2 + CE  

All other parameters and configurations remain identical between the two models. We then combine both models’ predictions via **Weighted Box Fusion (WBF)** for the final submission, aiming to capture more robust features and reduce overfitting.

---

## Training Overview

This repository demonstrates how to train a Faster R-CNN model for cell detection in whole slide images (WSIs) using [WholeSlideData](https://github.com/ComputationalPathologyGroup/wholeslidedata) and [Detectron2](https://github.com/facebookresearch/detectron2). It includes a pipeline setup for creating patches, preparing annotations, and running customized training.

### Main Libraries & Tools
- **WholeSlideData**  
  Handles patch sampling, annotation parsing, and data iteration.
- **Detectron2**  
  A flexible object detection library with a range of predefined models.

---

## Configuration Details

### WholeSlideData (`user_config`)

```yaml
wholeslidedata:
  default:
    yaml_source: "./configs/training_sample.yml"
    image_backend: "asap"
    labels:
      ROI: 0
      lymphocytes: 1

    batch_shape:
      batch_size: 10
      spacing: 0.5
      shape: [256, 256, 3]
      y_shape: [1000, 6]

    annotation_parser:
      sample_label_names: ['roi']

    point_sampler_name: "RandomPointSampler"
    point_sampler:
      buffer:
        spacing: ${batch_shape.spacing}
        value: -64

    patch_label_sampler_name: "DetectionPatchLabelSampler"
    patch_label_sampler:
      max_number_objects: 1000
      detection_labels: ['lymphocytes']
```

### Detectron2 Config
```
cfg.merge_from_file(
    model_zoo.get_config_file("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml")
)
cfg.DATASETS.TRAIN = ("detection_dataset2",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 1

cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 24, 32]]

cfg.SOLVER.IMS_PER_BATCH = 10
cfg.SOLVER.BASE_LR = 0.001
cfg.SOLVER.MAX_ITER = 2000
cfg.SOLVER.STEPS = (10, 100, 250)
cfg.SOLVER.WARMUP_ITERS = 0
cfg.SOLVER.GAMMA = 0.5
```


---


### Training Process 
1.	Batch Iterator Creation
Generates patches from WSIs based on user_config.
2.	Model Configuration
Loads a Faster R-CNN architecture from Detectron2’s model zoo.
3.	Trainer Execution
Runs WholeSlideDectectron2Trainer to train the model.
4.	Output
Saves logs, checkpoints, and final weights in ./outputs.

---

### Other Useful Scripts

In the utils folder, we provide:
	•	json_to_xml.py: Converts Grand Challenge JSON results to ASAP-compatible XML.
	•	plot_froc.py: Plots the FROC curve from metrics.json generated by the evaluation script.

These help visualize and evaluate detection results.


